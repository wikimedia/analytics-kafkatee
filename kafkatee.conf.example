#######################################################################
#                                                                     #
#                    kafkatee configuration file                      #
#                                                                     #
#                                                                     #
#######################################################################
#                                                                     #
# Syntax:                                                             #
#  <property-name> = <value>                                          #
#  input <type args..>                                                #
#  output <type arg..>                                                #
#                                                                     #
# Boolean property values:                                            #
#   >0, "true", "yes", "on", "" - interpreted as true                 #
#  everything else              - interpreted as false                #
#                                                                     #
#                                                                     #
# The configuration file consists of:                                 #
#   - Configuration properties (key = value) to control various       #
#     aspects of kafkatee.                                            #
#   - Inputs                                                          #
#   - Outputs                                                         #
#                                                                     #
#######################################################################


#######################################################################
#                                                                     #
# Configuration properties                                            #
#                                                                     #
#######################################################################


#######################################################################
#                                                                     #
# Kafka configuration                                                 #
#                                                                     #
# Kafka configuration properties are prefixed with "kafka."           #
# and topic properties are prefixed with "kafka.topic.".              #
#                                                                     #
# For the full range of Kafka handle and topic configuration          #
# properties, see:                                                    #
#  http://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md #
#                                                                     #
# And the Apache Kafka configuration reference:                       #
#  http://kafka.apache.org/08/configuration.html                      #
#                                                                     #
#######################################################################

# Initial list of kafka brokers
# Default: none
#kafka.metadata.broker.list = localhost

# Offset file directory.
# Each topic + partition combination has its own offset file.
# Default: current directory
#kafka.offset.store.path = /var/run/offsets/

# If the request offset was not found on broker, or there is no
# initial offset known (no stored offset), then reset the offset according
# to this configuration.
# Values: smallest (oldest/beginning), largest (newest/end), error (fail)
# Default: largest
#kafka.topic.auto.offset.reset = smallest

# Maximum message size.
# Should be synchronized on all producers, brokers and consumers.
# Default: 4000000
#kafka.message.max.bytes = 10000000

# Kafka debugging
# Default: none
#kafka.debug = msg,topic,broker







#######################################################################
#                                                                     #
# Message transformation                                              #
#                                                                     #
# A message read from one of the inputs may be transformed before     #
# being enqueued on the output queues.                                #
#                                                                     #
# Transformation requires that the input and output encoding differs, #
# i.e., 'input [encoding=json] ..' and 'output.encoding=string'       #
#                                                                     #
# While the input encoding is configured per input, the output        #
# encoding is configured globally, all outputs will receive the same  #
# message.                                                            #
#                                                                     #
# The currently supported transformation(s) are:                      #
#  JSON input -> string output:                                       #
#    JSON data is formatted according to the output.format            #
#    configuration. The %{field} syntax references the field in the   #
#    original JSON object by the same name and outputs its value.     #
#                                                                     #
# If the input and output encoding matches then the message remains   #
# untouched.                                                          #
#                                                                     #
# The output message delimiter (defaults to newline (\n)) is          #
# configurable (output.delimiter) and always appended to all output   #
# messages regardless of transformation.                              #
# The input is always stripped of its delimiter (which is newline     #
# for pipe inputs).                                                   #
#                                                                     #
#######################################################################


# Output encoding: string or json
# Default: string
#output.encoding = string


#######################################################################
# Output formatting                                                   #
#                                                                     #
# The format string is made up of %{..}-tokens and literals.          #
#                                                                     #
# Tokens:                                                             #
#                                                                     #
#  %{FIELD}                                                           #
#    Retrieves the value from the JSON object's field with the        #
#    same name.                                                       #
#                                                                     #
#  %{FIELD?DEFAULT}                                                   #
#    'DEFAULT' is the default string to use if no field was matched,  #
#     the default default string is "-".                              #
#                                                                     #
#  Literals are copied verbatim to the output string.                 #
#                                                                     #
#  Example JSON: {"task":19, "name":"Mike"}                           #
#  Example format: Got task %{task} for user %{name?unknown}          #
#  Example output: Got task 19 for user Mike                          #
#                                                                     #
# Note: Multi-level JSON objects are flattened:                       #
#       JSON:  {"a": {"b": 9}, "c": "hi"}                             #
#       Gives: { "b": 9, "c": "hi" }                                  #
#                                                                     #
#######################################################################

# Output format for JSON -> string transformation.
# Default: none
#output.format = %{hostname}        %{sequence}        %{dt}        %{time_firstbyte}        %{ip}        %{handling}/%{http_status}        %{bytes_sent}        %{request_method}        http://%{host}%{uri}%{query}        -        %{mime_type}        %{referer}        %{x_forwarded_for}        %{user_agent}        %{accept_language}        %{x_analytics}


# Output delimiter
# The output message ends with this delimiter.
# Supports \n, \r, \t, \0.
# Default: newline (\n)
#output.delimiter = ;END;\n


# Maximum queue size for each output, in number of messages
# Default: 100000
#output.queue.size = 1000000







#######################################################################
#                                                                     #
# Misc configuration                                                  #
#                                                                     #
#######################################################################

# Pid file location
# Default: /var/run/kafkatee.pid
#pid.file.path = kafkatee.pid

# Daemonize (background)
# Default: true
#daemonize = false

# Logging output level
# 1 = only emergencies .. 6 = info, 7 = debug
# Default: 6 (info)
#log.level = 7


#
# JSON Statistics
#
# Statistics is collected from kafkatee itself(*) as well as librdkafka
# Each JSON object has a top level key of either 'kafkatee' or
# 'kafka' to indicate which type of statistics the object contains.
# Each line is a valid JSON object.
#
# *: kafkatee does not currently output any stats of its own, just from rdkafka.
#

# Statistics output interval
# Defaults to 60 seconds, use 0 to disable.
#log.statistics.interval = 60

# Statistics output file
# Defaults to /tmp/kafkatee.stats.json
#log.statistics.file = /tmp/kafkatee.stats.json


# Command to run on startup, before starting IO.
# Default: none
#command.init = ./my-script.sh

# Command to run on termination after all IOs have been stopped.
# Default: none
#command.term = ./my-cleanup-script.sh


# Include other config file
#include local.conf

# Set environment variable which will be available for all sub-sequent
# command executions (command.*, input pipe, output pipe, ..)
#setenv.NMSGS=12
# clear:
#setenv.LD_LIBRARY_PATH=



#######################################################################
#                                                                     #
# Inputs                                                              #
#                                                                     #
# The following types of inputs are supported:                        #
#  - Kafka consumer                                                   #
#  - Piped command                                                    #
#                                                                     #
# Any number and mix of inputs can be configured.                     #
# Each input may be configured with an optional list of               #
# input-specific configuration properties, called the key-values.     #
#                                                                     #
# Supported key-values:                                               #
#  - encoding=string|json     - message encoding from this input.     #
#                               Default: string                       #
#                                                                     #
#  - stop.eof=true|false      - do not continue try reading from      #
#                               this input when EOF has been reached  #
#                               Default: false                        #
#                                                                     #
#  - stop.error=true|false    - do not reopen/restart input on error. #
#                               Default: false                        #
#                                                                     #
# The key-values is CSV-separated and the list of key-values must be  #
# enveloped by brackets: [encoding=string,foo=bar]                    #
#                                                                     #
#######################################################################

#######################################################################
# Kafka consumer input syntax:                                        #
#  input [key-values] kafka topic <topic> partition <N> from <offset> #
#                                                                     #
# where:                                                              #
#  - [key-values] is an optional CSV-separated list of key-values.    #
#    NOTE: the enveloping brackets are literal.                       #
#  - <topic> is the Kafka topic to consume from.                      #
#  - <N> or <N>-<M> is the partition, or range of partitions, to      #
#    consume from.                                                    #
#  - <offset> is the offset to start consuming from.                  #
#    supported values: beginning, end, stored, <number>               #
#    Where 'stored' means to use a local offset file to store and     #
#    read the offset from, which allows a later run of kafkatee       #
#    to pick up from where it left off.                               #
#                                                                     #
#######################################################################

#input [encoding=json] kafka topic varnish partition 0-10 from stored
#input [encoding=string] kafka topic test1 partition 0 from end


#######################################################################
# Piped command input syntax:                                         #
#  input [key-values] pipe <command ...>                              #
#                                                                     #
# where:                                                              #
#  - [key-values] is an optional CSV-separated list of key-values.    #
#    NOTE: the enveloping brackets are literal.                       #
#  - <command ...> is a command string that will be executed with:    #
#      /bin/sh -c "<command ...>", thus supporting pipes, etc.        #
#                                                                     #
#######################################################################

#input [encoding=string] pipe tail -f a.log | grep -v ^DEBUG:
#input pipe wget -q -O- http://example.com/api/events






#######################################################################
#                                                                     #
# Outputs                                                             #
#                                                                     #
# The following types of outputs are supported:                       #
#  - Piped command                                                    #
#  - File                                                             #
#                                                                     #
# Each output has its own queue where messages are enqueued prior to  #
# writing to the output, this queue is limited by output.queue.size.  #
# If the queue limit is reached no new messages are added to the      #
# queue (tail-drop).                                                  #
#                                                                     #
# Outputs are configured with a sample rate, 1 means every message,   #
# 2 means every other message, 1000 means every 1000nd message, and   #
# so on.                                                              #
#                                                                     $
# If an output process terminates, or an output file fails writing,   #
# the output is closed and reopened/restarted. The messages in the    #
# output's queue remain in the queue while the output is unavailable. #
#                                                                     #
#######################################################################


#######################################################################
# Piped command output syntax:                                        #
#  output pipe <sample-rate> <command ...>                            #
#                                                                     #
# where:                                                              #
#  - <sample-rate> is the sample-rate: 1 for each message, 100 for    #
#    every 100rd message, and so on.                                  #
#  - <command ...> is a command string that will be executed with:    #
#      /bin/sh -c "<command ...>", thus supporting pipes, etc.        #
#                                                                     #
# Output pipes are stopped and restarted if kafkatee receives a       #
# SIGHUP signal.                                                      #
#######################################################################

#output pipe 1 grep ^Something >> somefile.log
#output pipe 1000 do-some-stats.sh
#output pipe 1 nc -u syslog.example.com 514


#######################################################################
# File output syntax:                                                 #
#  output file <sample-rate> <path>                                   #
#                                                                     #
# where:                                                              #
#  - <sample-rate> is the sample-rate: 1 for each message, 100 for    #
#    every 100rd message, and so on.                                  #
#  - <path> is the file path to write. The file is appended.          #
#                                                                     #
# Output files are closed and reopened if kafkatee receives a         #
# SIGHUP signal, thus allowing log file rotation.                     #
#######################################################################

#output file 100 /tmp/sampled-100.txt